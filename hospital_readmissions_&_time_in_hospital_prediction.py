# -*- coding: utf-8 -*-
"""Hospital Readmissions & Time In Hospital Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JYGkhEvmjnIg0qoNFxL1yz-PIYMKqAIt

# **EDA**
"""

import pandas as pd
import numpy as np

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
import seaborn as sns
# %matplotlib inline

import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv("train.csv")
df.head()

df.drop(['number_outpatient', 'number_emergency', 'number_inpatient'], axis=1, inplace=True)

"""# **Data Visualization**

## **Two graphs maximum**
"""

df.columns

fig = px.scatter(df, x='time_in_hospital', y='num_lab_procedures', color='readmitted')
fig.show()

fig = px.scatter(df, x='time_in_hospital', y='num_medications', color='readmitted')
fig.show()

fig = px.histogram(df, x='diag_1_428', color='readmitted')
fig.show()

fig = px.histogram(df, x='diag_3_276', color='readmitted')
fig.show()

fig = px.box(df, y="num_lab_procedures", color="readmitted")
fig.show()

fig = px.scatter_3d(df, x='time_in_hospital', y='num_lab_procedures', z='num_medications', symbol='diabetesMed_Yes', size='time_in_hospital', size_max=20,
                    color='readmitted')
fig.show()

z = df.pivot_table(
    values='time_in_hospital',
    index='diag_1_428',
    columns='readmitted',
    aggfunc='count'
).values

x = df['diag_1_428'].unique() # X-axis variable
y = ['Not Readmitted', 'Readmitted'] # Y-Axis variable

fig = go.Figure(
    data=[go.Surface(z=z, x=x, y=y, colorscale='Viridis')]
)

# Customize layout
fig.update_layout(
    title="3D surface Plot of Time in Hospital",
    scene=dict(
        xaxis_title='Number of Lab Procedures',
        yaxis_title='Number of Medications',
        zaxis_title='Time in Hospital'
    )
)
fig.show()

df.columns

# Make a race column (African American or Caucasian) and a gender column
df['race'] = df.apply(lambda x: 1 if x['race_AfricanAmerican'] == True else (0 if x['race_Caucasian'] == True else None), axis=1)
df['gender'] = df.apply(lambda x: 1 if x['gender_Female'] == True else 0, axis=1)

"""# In all Graphs, for race, African American = 1, Caucasian = 0

# In all Graphs, for gender, Female = 1, Male = 0
"""

# Boxplot for time_in_hospital across race
plt.figure(figsize=(10, 6))
sns.boxplot(x='race', y='time_in_hospital', data=df)
plt.title("Boxplot of Time in Hospital by Race")
plt.xlabel("Race")
plt.ylabel("Time in Hospital")
plt.show()

# Boxplot for time_in_hospital across gender
plt.figure(figsize=(10, 6))
sns.boxplot(x='gender', y='time_in_hospital', data=df)
plt.title("Boxplot of Time in Hospital by Gender")
plt.xlabel("Gender")
plt.ylabel('Time in Hospital')
plt.show()

# Barplot of average number of diagnoses by race
plt.figure(figsize=(10, 6))
sns.barplot(x='race', y='number_diagnoses', data=df, errorbar=None)
plt.title("Average Number of Diagnoses by Race")
plt.show()

# countplot for distirubtion of gender
plt.figure(figsize=(10, 6))
sns.countplot(x='gender', data=df)
plt.title("Countplot of Gender")
plt.show()

df.columns

# Violin plot for time_in_hospital across gender
plt.figure(figsize=(10, 6))
sns.violinplot(x='gender', y='time_in_hospital', data=df)
plt.title("Violin Plot of Time in Hospital by Gender")
plt.xlabel("Gender")
plt.ylabel("Time in Hospital")
plt.show()

# Violin plot for time_in_hospital across race
plt.figure(figsize=(10, 6))
sns.violinplot(x='race', y='time_in_hospital', data=df)
plt.title("Violin Plot of Time in Hospital by Race")
plt.xlabel("Race")
plt.ylabel("Time in Hospital")
plt.show()

"""# **Preprocessing -> Pipeline**
## Regression -> Classification Models
"""

# Preprocessing
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.decomposition import PCA
from sklearn.ensemble import VotingRegressor

# Regression Models
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet

# Classification Models
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier

# Evaluation Metrics
from sklearn.metrics import confusion_matrix, classification_report, f1_score, recall_score, precision_score, mean_squared_error, r2_score

"""**Define Features and Targets**"""

# Seperate Target variables
y_reg = df['time_in_hospital']
y_clf = df['readmitted']

# Drop target variables from features
X_reg = df.drop(['time_in_hospital', 'readmitted'], axis=1)
X_clf = df.drop(['readmitted'], axis=1)

# Identify numerical columns
numerical_cols_reg = X_reg.select_dtypes(include=np.number).columns.tolist()
numerical_cols_clf = X_clf.select_dtypes(include=np.number).columns.tolist()

# Identify categorical columns
categorical_cols_reg = X_reg.select_dtypes(include='object').columns.tolist()
categorical_cols_clf = X_clf.select_dtypes(include='object').columns.tolist()

# Print Numerical columns
print(f"Numerical columns for Regression: {numerical_cols_reg}")
print(f"Numerical columns for Classification: {numerical_cols_clf}")

# Categorical columns is the same for reg and clf
print(f"Categorical columns: {categorical_cols_reg}")

# Split the Data into Training and Testing Sets
X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(
    X_reg, y_reg, test_size=0.2, random_state=42
)

X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(
    X_clf, y_clf, test_size=0.2, random_state=42
)

"""**Outlier Detection and Treatment**"""

from sklearn.covariance import EllipticEnvelope

# Detect outleirs in numerical features
outlier_detector = EllipticEnvelope(contamination=0.01, random_state=42)
outlier_detector.fit(X_train_reg[numerical_cols_reg])

# Idnetify outliers (reg)
outliers = outlier_detector.predict(X_train_reg[numerical_cols_reg]) == -1
print(f"Number of outliers: {outliers.sum()}")

# Remove outliers
X_train_reg = X_train_reg[~outliers]
y_train_reg = y_train_reg[~outliers]

# Detect outliers in classification features
outlier_detector = EllipticEnvelope(contamination=0.01, random_state=42)
outlier_detector.fit(X_train_clf[numerical_cols_clf])

# Identify outliers( clf)
outliers = outlier_detector.predict(X_train_clf[numerical_cols_clf]) == -1
print(f"Number of outliers: {outliers.sum()}")

# Remove outliers
X_train_clf = X_train_clf[~outliers]
y_train_clf = y_train_clf[~outliers]

# Oversampling the Minority Class - using methods like SMOTE (Synthetic Minority Over-sampling Technique)
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train_clf, y_train_clf)

# check class distirubtion
class_counts = df['readmitted'].value_counts()
print(class_counts)

# Visualize the distribution
import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x='readmitted', data=df)
plt.title('Class Distribution of Readmissions')
plt.show()

# Majority Class Predictor
majority_class = df['readmitted'].mode()[0]
baseline_accuracy = (df['readmitted'] == majority_class).mean()
print(f"Baseline Accuracy: {baseline_accuracy}")

"""**StandardScaler() and OneHotEncoder() the data should come after splitting the data between training and test set, because the test set plays the role of fresh unseen data, so it's not supposed to be accessible at the training stage. Using any information comign from the test set before or during training is a potential bias in the evaluation of the performance.**"""

# Numerical Pipeline: Impute missing values -> scale
numerical_pipeline= Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

# Categorical Pipeline: Impute missing values, then encode
categorical_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

# Combine Numerical and Categorical Pipelines into a ColumnTransformer
preprocessing_pipeline = ColumnTransformer(transformers=[
    ('num', numerical_pipeline, numerical_cols_reg),
    ('cat', categorical_pipeline, categorical_cols_reg)
])

# Regression pipeline
regression_pipeline = Pipeline(steps=[
    ('num_pipeline', preprocessing_pipeline),
    ('pca', PCA(n_components=0.95, random_state=42)), # Retain 95% variance
    ('model', LinearRegression())
])

ridge_pipeline = Pipeline(steps=[
    ('num_pipeline', preprocessing_pipeline),
    ('ridge', Ridge())
])

lasso_pipeline = Pipeline(steps=[
    ('num_pipeline', preprocessing_pipeline),
    ('lasso', Lasso())
])

elastic_net_pipeline = Pipeline(steps=[
    ('num_pipeline', preprocessing_pipeline),
    ('pca', PCA(n_components=0.95, random_state=42)),
    ('elastic_net', ElasticNet())
])

regression_pipeline = VotingRegressor([
    ('model', regression_pipeline),
    ('ridge', ridge_pipeline),
    ('lasso', lasso_pipeline),
    ('elastic_net', elastic_net_pipeline)
])

reg_param_grid = [
    {
        'model': [LinearRegression()],
        'model__fit_intercept': [True, False],
        'model__n_jobs': [1, 2, 5]
    },
    {
        'model': [Ridge()],
        'model__alpha': [0.1, 1.0, 10.0],
        'model__fit_intercept': [True, False]
    },
    {
        'model': [Lasso()],
        'model__alpha': [0.1, 1.0, 10.0],
        'model__fit_intercept': [True, False],
    },
    {
        'model': [ElasticNet()],
        'model__alpha': [0.1, 1.0, 10.0],
        'model__l1_ratio': [0.2, 0.5, 0.8],
        'model__fit_intercept': [True, False],
    }
]

reg_grid_search = GridSearchCV(
    estimator=regression_pipeline,
    param_grid=reg_param_grid,
    cv=5, # 5-fold cross-validation
    scoring='neg_mean_squared_error',
    n_jobs=-1,
    verbose=2
)

reg_grid_search.fit(X_train_reg, y_train_reg)
print(f"Best parameters: {reg_grid_search.best_params_}")
print(f"Best CV Score (Neg MSE): {reg_grid_search.best_score_}")

"""# **Evaluating the Best Regression Model**"""

# Best regression model
best_reg_model = reg_grid_search.best_estimator_

# Predict on test data
y_pred_reg = best_reg_model.predict(X_test_reg)

# Evaluation metrics
mse = mean_squared_error(y_test_reg, y_pred_reg)
r2 = r2_score(y_test_reg, y_pred_reg)
print("Regression Model Evaluation: \n")
print(f"mean Squared Error (MSE): {mse}")
print(f"R-squared (R²): {r2}")

# Visualization: Actual vs Predicted
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test_reg, y=y_pred_reg, alpha=0.5)
plt.xlabel("Actual Time in Hospital")
plt.ylabel('Predicted Time in Hospital')
plt.title('Actual vs Predicted Time in Hospital')
plt.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--')
plt.show()

"""# **Classification Models**"""

# Numerical Pipeline: Impute missing values -> scale
numerical_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

# Categorical Pipeline: Impute missing values, then encode
categorical_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

# Combine Numerical and Categorical Pipelines into a ColumnTransformer
preprocessing_pipeline = ColumnTransformer(transformers=[
    ('num', numerical_pipeline, numerical_cols_clf),
    ('cat', categorical_pipeline, categorical_cols_clf)
])

# Logistic Regression Pipeline
logistic_pipeline = Pipeline(steps=[
    ('pipeline', preprocessing_pipeline),
    ('model', LogisticRegression())
])

# Decision Tree Classifier Pipeline
decision_tree_clf_pipeline = Pipeline(steps=[
    ('pipeline', preprocessing_pipeline),
    ('decision_tree_clf', DecisionTreeClassifier())
])

# Random Forest Classifier Pipeline
random_forest_clf_pipeline = Pipeline(steps=[
    ('pipeline', preprocessing_pipeline),
    ('random_forest_clf', RandomForestClassifier())
])

# K-Neighbors Classifier Pipeline
k_neighbors_clf_pipeline = Pipeline(steps=[
    ('pipeline', preprocessing_pipeline),
    ('k_neighbors_clf', KNeighborsClassifier())
])

# Gradient-Boosting Pipeline
gradient_boosting_clf_pipeline = Pipeline(steps=[
    ('pipeline', preprocessing_pipeline),
    ('gradient_boosting_clf', GradientBoostingClassifier())
])

# XGBoost Classifier Pipeline
xgboost_clf_pipeline = Pipeline(steps=[
    ('pipeline', preprocessing_pipeline),
    ('xgboost_clf', XGBClassifier())
])

# Create an estimators list with the name of all the pipelines
estimators = [logistic_pipeline, decision_tree_clf_pipeline, random_forest_clf_pipeline, k_neighbors_clf_pipeline, gradient_boosting_clf_pipeline, xgboost_clf_pipeline]

"""## Classification param_grids"""

# Logistic Classification grid
clf_param_grid_logistic = {
    'model__penalty': ['l1', 'l2', 'elasticnet', 'none'],
}

# Decision Tree grid
# Make sure the decision_tree_clf__[feature] is the same as the name of the step of the classifier in the pipeline
clf_param_grid_decision_tree = {
    'decision_tree_clf__criterion': [None, 'gini', 'entropy'],
    'decision_tree_clf__max_depth': [None, 10, 20],
    'decision_tree_clf__min_samples_split': [None, 2, 5, 10],
    'decision_tree_clf__min_samples_leaf': [None, 1, 2, 4],
    'decision_tree_clf__max_features': [None, 'auto', 'sqrt', 'log2'],
}

# Random Forest grid
# Make sure the random_forest_clf__[feature] is the same as the name of the step of the classifier in the pipeline
clf_param_grid_random_forest = {
    'random_forest_clf__n_estimators': [None, 50, 100, 200],
    'random_forest_clf__max_depth': [None, 10, 20],
    'random_forest_clf__min_samples_split': [None, 2, 5, 10]
}

# K-Nieghbors grid
clf_param_grid_k_neighbors = {
    'k_neighbors_clf__n_neighbors': [None, 3, 5, 7],
    'k_neighbors_clf__weights': [None, 'uniform', 'distance'],
}

# Gradient Boosting grid
clf_param_grid_gradient_boosting = {
    # Make sure the name is the same as the name of the step of the classifier in the pipeline so the RandomizedSearchCV
    # Knows what to apply the parameters to
    'gradient_boosting_clf__n_estimators': [None, 50, 100, 200],
    'gradient_boosting_clf__learning_rate': [None, 0.01, 0.1, 1],
}

# XGBoost grid
clf_param_grid_xgboost = {
    'xgboost_clf__n_estimators': [None, 50, 100, 200],
    'xgboost_clf__max_depth': [None, 3, 5, 7],
    'xgboost_clf__max_depth': [None, 3, 6, 10],
}

param_grids = [
    clf_param_grid_logistic,
    clf_param_grid_decision_tree,
    clf_param_grid_random_forest,
    clf_param_grid_k_neighbors,
    clf_param_grid_gradient_boosting,
    clf_param_grid_xgboost
]

"""## **Use RandomizedSearchCV in a for loop, to reduce lag**"""

# Use a for loop to RandomizedSearchCV over estimators & param_grids
# Use zip to parse both lists
for estimator, param_grid in zip(estimators, param_grids):

    clf_random_search = RandomizedSearchCV(
        estimator=estimator,
        param_distributions=param_grid,
        n_iter=5, # Number of parameters to test
        cv=2, # 2-fold cross-validation
        scoring='recall', # Recall is more important since minimizing false negatives is crucial
        n_jobs=2,
        verbose=2,
        random_state=42
    )

    # Fit the model
    clf_random_search.fit(X_train_clf, y_train_clf)

    # Best classification parameters and Recall Score
    print(f"Best parameters: {clf_random_search.best_params_}")
    print(f"Best Score: {clf_random_search.best_score_}")

    # y_pred_clf
    y_pred_clf = clf_random_search.predict(X_test_clf)

    # evaluation metrics
    print(f"Classification Model Evaluation: {classification_report(y_test_clf, y_pred_clf)}")

    # ROC-AUC Score
    from sklearn.metrics import roc_auc_score, roc_curve

    # Ensure classifier can predict probabilities
    y_pred_proba = clf_random_search.best_estimator_.predict_proba(X_test_clf)[:, 1]
    roc_auc = roc_auc_score(y_test_clf, y_pred_proba)
    fpr, tpr, thresholds = roc_curve(y_test_clf, y_pred_proba)

    # Plot the ROC curve
    plt.figure()
    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], 'k--') # Diagnol line
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend()
    plt.show()

    # Confusion Matrix
    conf_mat = confusion_matrix(y_test_clf, y_pred_clf)
    plt.figure(figsize=(6, 4))
    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='RdBu',
                xticklabels=['Not Readmitted', 'Readmitted'],
                yticklabels=['Not Readmitted', 'Readmitted'])
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.title('Confusion Matrix')
    plt.show()